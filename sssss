#!/usr/bin/env python3
"""
Lightweight PlanIT API Connect Mapping Script - Remote Navigation
================================================================
One-time execution script to map PlanIT application IDs to API Connect specifications
by navigating repositories remotely instead of cloning.
"""

import os
import csv
import yaml
import json
import requests
import base64
import time
from urllib.parse import urlparse
from pathlib import Path

SPREADSHEET_PATH = "planit_apps.csv"
OUTPUT_FILE = "planit_api_mapping.csv"

GITHUB_TOKEN = os.environ.get('GITHUB_TOKEN')
REQUEST_DELAY = 0.1

def load_active_apps():
    apps = []
    with open(SPREADSHEET_PATH, 'r') as f:
        reader = csv.DictReader(f)
        for row in reader:
            if (row.get('App State', '').lower() == 'active' and 
                row.get('Repository State', '').lower() == 'active' and
                row.get('Repository URI', '')):
                apps.append({
                    'app_id': row.get('App ID', '').strip(),
                    'app_name': row.get('App Name', '').strip(),
                    'repo_name': row.get('Repository Name', row.get('Repistory Name', '')).strip(),
                    'repo_uri': row.get('Repository URI', '').strip()
                })
    return apps

def parse_repo_url(repo_uri):
    parsed = urlparse(repo_uri)
    
    if 'github.com' in parsed.netloc:
        path_parts = parsed.path.strip('/').replace('.git', '').split('/')
        if len(path_parts) >= 2:
            return {
                'owner': path_parts[0],
                'repo': path_parts[1],
                'base_url': f"https://api.github.com/repos/{path_parts[0]}/{path_parts[1]}"
            }
    
    return None

def get_request_headers():
    if GITHUB_TOKEN:
        return {'Authorization': f'token {GITHUB_TOKEN}'}
    return {}

def get_tree_contents(repo_info, path=''):
    headers = get_request_headers()
    
    try:
        url = f"{repo_info['base_url']}/contents/{path}" if path else f"{repo_info['base_url']}/contents"
        
        response = requests.get(url, headers=headers, timeout=30)
        time.sleep(REQUEST_DELAY)
        
        if response.status_code == 200:
            return response.json()
        else:
            print(f"    API Error {response.status_code}: {response.text[:100]}")
            return []
    except requests.exceptions.RequestException as e:
        print(f"    Request failed: {str(e)}")
        return []

def find_yaml_files_remote(repo_info, path='', max_depth=10, current_depth=0):
    if current_depth >= max_depth:
        return []
    
    yaml_files = []
    contents = get_tree_contents(repo_info, path)
    
    if not contents:
        return yaml_files
    
    for item in contents:
        item_name = item.get('name', '')
        item_path = item.get('path', '')
        item_type = item.get('type', '')
        
        if item_name.startswith('.') or item_name in ['node_modules', '__pycache__', 'build', 'dist', 'target']:
            continue
        
        if item_type == 'file' and item_name.lower().endswith(('.yaml', '.yml')):
            yaml_files.append(item_path)
        elif item_type == 'dir' and current_depth < max_depth - 1:
            yaml_files.extend(find_yaml_files_remote(repo_info, item_path, max_depth, current_depth + 1))
    
    return yaml_files

def get_file_content(repo_info, file_path):
    headers = get_request_headers()
    
    try:
        url = f"{repo_info['base_url']}/contents/{file_path}"
        
        response = requests.get(url, headers=headers, timeout=30)
        time.sleep(REQUEST_DELAY)
        
        if response.status_code == 200:
            data = response.json()
            
            if data.get('encoding') == 'base64':
                content = base64.b64decode(data['content']).decode('utf-8')
                return content
        
        return None
    except Exception as e:
        print(f"    Failed to get file content for {file_path}: {str(e)}")
        return None

def parse_yaml_content(content):
    try:
        return yaml.safe_load(content)
    except Exception as e:
        return None

def is_openapi_spec(content):
    if not isinstance(content, dict):
        return False
    
    has_openapi = 'openapi' in content or 'swagger' in content
    has_ibm_name = content.get('info', {}).get('x-ibm-name')
    has_paths = 'paths' in content
    
    return has_openapi and (has_ibm_name or has_paths)

def is_product_spec(content):
    if not isinstance(content, dict):
        return False
    
    return (content.get('product') and 
            content.get('info', {}).get('name'))

def extract_api_name(content, spec_type):
    info = content.get('info', {})
    
    if spec_type == 'openapi':
        return info.get('x-ibm-name') or info.get('title')
    elif spec_type == 'product':
        return info.get('name')
    
    return None

def process_repo_remote(app):
    results = []
    
    repo_info = parse_repo_url(app['repo_uri'])
    if not repo_info:
        print(f"    Unsupported repository URL format")
        return results
    
    yaml_files = find_yaml_files_remote(repo_info)
    print(f"    Found {len(yaml_files)} YAML files")
    
    for yaml_file in yaml_files:
        content_str = get_file_content(repo_info, yaml_file)
        if not content_str:
            continue
        
        content = parse_yaml_content(content_str)
        if not content:
            continue
        
        folder_path = str(Path(yaml_file).parent) if yaml_file else ''
        
        if is_openapi_spec(content):
            api_name = extract_api_name(content, 'openapi')
            if api_name:
                results.append({
                    'PlanIT_App_ID': app['app_id'],
                    'PlanIT_App_Name': app['app_name'],
                    'Repository_Name': app['repo_name'],
                    'File_Path': yaml_file,
                    'Spec_Type': 'openapi',
                    'API_Name': api_name,
                    'Folder_Path': folder_path
                })
                print(f"      OpenAPI: {api_name}")
        
        elif is_product_spec(content):
            product_name = extract_api_name(content, 'product')
            if product_name:
                results.append({
                    'PlanIT_App_ID': app['app_id'],
                    'PlanIT_App_Name': app['app_name'],
                    'Repository_Name': app['repo_name'],
                    'File_Path': yaml_file,
                    'Spec_Type': 'product',
                    'API_Name': product_name,
                    'Folder_Path': folder_path
                })
                print(f"      Product: {product_name}")
    
    return results

def main():
    print("PlanIT API Connect Mapping Script - Remote Navigation")
    print("=" * 60)
    
    if not GITHUB_TOKEN:
        print("Warning: No GitHub token found. Rate limits may apply.")
        print("Set GITHUB_TOKEN environment variable for better performance.")
    
    print("\nLoading PlanIT applications...")
    apps = load_active_apps()
    print(f"Found {len(apps)} active applications")
    
    all_results = []
    
    for i, app in enumerate(apps, 1):
        print(f"\n[{i}/{len(apps)}] Processing: {app['app_name']} ({app['app_id']})")
        try:
            results = process_repo_remote(app)
            all_results.extend(results)
        except Exception as e:
            print(f"    Error processing repository: {str(e)}")
            continue
    
    if all_results:
        with open(OUTPUT_FILE, 'w', newline='') as csvfile:
            fieldnames = ['PlanIT_App_ID', 'PlanIT_App_Name', 'Repository_Name', 
                        'File_Path', 'Spec_Type', 'API_Name', 'Folder_Path']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(all_results)
        
        print(f"\nResults written to: {OUTPUT_FILE}")
        print(f"Total specifications found: {len(all_results)}")
        print(f"   - OpenAPI specs: {len([r for r in all_results if r['Spec_Type'] == 'openapi'])}")
        print(f"   - Product specs: {len([r for r in all_results if r['Spec_Type'] == 'product'])}")
        
        repo_summary = {}
        for result in all_results:
            repo_name = result['Repository_Name']
            if repo_name not in repo_summary:
                repo_summary[repo_name] = {'openapi': 0, 'product': 0}
            repo_summary[repo_name][result['Spec_Type']] += 1
        
        print(f"\nRepository Summary:")
        for repo, counts in repo_summary.items():
            print(f"   {repo}: {counts['openapi']} OpenAPI, {counts['product']} Product")
    else:
        print("\nNo API Connect specifications found")
    
    print("\nScript completed successfully!")

if __name__ == "__main__":
    main()
